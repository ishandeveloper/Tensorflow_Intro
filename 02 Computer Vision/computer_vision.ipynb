{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision\n",
    "#### Author : ishandeveloper\n",
    "Computer vision is the field of having a computer understand and label what is present in an image.\n",
    "\n",
    "One way to achieve this is to use lots of pictures of clothing and tell the computer what that's a picture of and then have the computer figure out the patterns that give you the difference between a shoe, and a shirt, and a handbag, and a coat for example. That's what we're going to learn how to do in this section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using <b>'Fashion MNIST dataset'</b> for this, which contains more than 70,000 images of clothes categorized into different items such as shirts, shoes etc. each scaled down to a resolution of 28x28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Importing MNIST dataset using Tensorflow API Call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu ),\n",
    "    keras.layers.Dense(10,  activation=tf.nn.softmax)\n",
    "]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "↑ Now we have three layers. The important things to look at are the first and the last layers. The last layer has 10 neurons in it because we have ten classes of clothing in the dataset. They should always match. The first layer is a flatten layer with the input shaping 28 by 28. Now, if you remember our images are 28 by 28, so we're specifying that this is the shape that we should expect the data to be in. Flatten takes this 28 by 28 square and turns it into a simple linear array. The interesting stuff happens in the middle layer, sometimes also called a hidden layer. This is a 128 neurons in it, and I'd like you to think about these as variables in a function. Maybe call them x1, x2 x3, etc. Now, there exists a rule that incorporates all of these that turns the 784 values of an ankle boot into the value nine, and similar for all of the other 70,000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential: That defines a SEQUENCE of layers in the neural network\n",
    "\n",
    "Flatten: Remember earlier where our images were a square, when you printed them out? Flatten just takes that square and turns it into a 1 dimensional set.\n",
    "\n",
    "Dense: Adds a layer of neurons\n",
    "\n",
    "Each layer of neurons need an activation function to tell them what to do. There's lots of options, but just use these for now.\n",
    "\n",
    "Relu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
    "\n",
    "Softmax takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Example\n",
    "Let's plot these raw values as an image to make it easier to inspect. I can also print out the raw values so we can see what they look like. Here you can see the raw values for the pixel numbers from zero to 255,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Image Is Labelled By The Neural Network As 9\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.93933632e-08 4.42263282e-08 6.14911516e-09 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.36504429e-10 0.00000000e+00 0.00000000e+00\n",
      "  2.36504429e-10 0.00000000e+00 0.00000000e+00 4.23342928e-08\n",
      "  5.67610630e-08 5.60515497e-08 6.03086294e-08 5.67610630e-08\n",
      "  3.28741156e-08 1.96298676e-08 1.51362835e-08 1.01696904e-08\n",
      "  1.41902657e-08 1.27712392e-08 0.00000000e+00 2.36504429e-10]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.36504429e-10 0.00000000e+00 0.00000000e+00\n",
      "  2.36504429e-10 0.00000000e+00 1.37172569e-08 5.65245585e-08\n",
      "  5.25039833e-08 5.53420364e-08 5.62880541e-08 5.81800895e-08\n",
      "  5.95991161e-08 6.00721250e-08 6.03086294e-08 5.86530984e-08\n",
      "  6.03086294e-08 4.42263282e-08 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.73008858e-10 7.09513287e-10\n",
      "  0.00000000e+00 0.00000000e+00 4.58818592e-08 5.65245585e-08\n",
      "  5.34500010e-08 5.60515497e-08 5.55785408e-08 5.48690275e-08\n",
      "  5.43960187e-08 5.53420364e-08 5.53420364e-08 5.51055320e-08\n",
      "  5.88896028e-08 4.04422574e-08 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 2.36504429e-10 2.36504429e-10 0.00000000e+00\n",
      "  0.00000000e+00 2.36504429e-09 6.03086294e-08 5.34500010e-08\n",
      "  5.72340718e-08 5.65245585e-08 5.62880541e-08 5.65245585e-08\n",
      "  5.67610630e-08 5.65245585e-08 5.72340718e-08 5.62880541e-08\n",
      "  5.86530984e-08 4.54088504e-08 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 4.06787618e-08 5.79435851e-08 5.41595143e-08\n",
      "  5.67610630e-08 5.69975674e-08 5.67610630e-08 5.69975674e-08\n",
      "  5.74705763e-08 5.74705763e-08 5.69975674e-08 5.36865054e-08\n",
      "  5.91261073e-08 4.94294257e-08 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.41902657e-09 1.18252215e-09 0.00000000e+00\n",
      "  1.46632746e-08 6.03086294e-08 5.43960187e-08 5.58150453e-08\n",
      "  5.65245585e-08 5.69975674e-08 5.72340718e-08 5.69975674e-08\n",
      "  5.72340718e-08 5.72340718e-08 5.62880541e-08 5.62880541e-08\n",
      "  5.72340718e-08 5.98356206e-08 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 7.09513287e-10 0.00000000e+00 0.00000000e+00\n",
      "  6.03086294e-08 5.55785408e-08 5.39230098e-08 5.77070807e-08\n",
      "  5.69975674e-08 5.69975674e-08 5.77070807e-08 5.74705763e-08\n",
      "  5.74705763e-08 5.77070807e-08 5.74705763e-08 5.65245585e-08\n",
      "  5.55785408e-08 6.03086294e-08 5.20309744e-09 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.81800895e-08\n",
      "  5.39230098e-08 5.20309744e-08 5.79435851e-08 5.74705763e-08\n",
      "  5.60515497e-08 5.69975674e-08 5.72340718e-08 5.72340718e-08\n",
      "  5.72340718e-08 5.74705763e-08 5.65245585e-08 5.60515497e-08\n",
      "  5.55785408e-08 5.98356206e-08 2.50694695e-08 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 7.09513287e-10 9.46017716e-10\n",
      "  9.46017716e-10 4.73008858e-10 2.36504429e-10 0.00000000e+00\n",
      "  0.00000000e+00 4.25707972e-09 5.74705763e-08 5.39230098e-08\n",
      "  5.46325231e-08 5.69975674e-08 5.74705763e-08 5.60515497e-08\n",
      "  5.62880541e-08 5.72340718e-08 5.69975674e-08 5.67610630e-08\n",
      "  5.67610630e-08 5.67610630e-08 5.55785408e-08 5.60515497e-08\n",
      "  5.58150453e-08 5.81800895e-08 5.53420364e-08 0.00000000e+00]\n",
      " [2.36504429e-10 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  5.20309744e-09 6.03086294e-08 5.62880541e-08 5.36865054e-08\n",
      "  5.62880541e-08 5.65245585e-08 5.60515497e-08 5.69975674e-08\n",
      "  5.69975674e-08 5.60515497e-08 5.58150453e-08 5.62880541e-08\n",
      "  5.65245585e-08 5.65245585e-08 5.65245585e-08 5.65245585e-08\n",
      "  5.65245585e-08 5.60515497e-08 6.03086294e-08 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 5.91261073e-09 1.96298676e-08 3.97327441e-08\n",
      "  6.03086294e-08 5.32134965e-08 5.32134965e-08 5.55785408e-08\n",
      "  5.39230098e-08 5.43960187e-08 5.36865054e-08 5.32134965e-08\n",
      "  5.36865054e-08 5.46325231e-08 5.48690275e-08 5.60515497e-08\n",
      "  5.67610630e-08 5.58150453e-08 5.62880541e-08 5.65245585e-08\n",
      "  5.65245585e-08 5.55785408e-08 5.93626117e-08 1.46632746e-08]\n",
      " [0.00000000e+00 3.90232308e-08 5.32134965e-08 5.20309744e-08\n",
      "  5.29769921e-08 6.03086294e-08 6.03086294e-08 5.51055320e-08\n",
      "  5.41595143e-08 5.27404877e-08 5.36865054e-08 5.39230098e-08\n",
      "  5.46325231e-08 5.48690275e-08 5.55785408e-08 5.60515497e-08\n",
      "  5.51055320e-08 5.43960187e-08 5.39230098e-08 5.43960187e-08\n",
      "  5.51055320e-08 5.48690275e-08 5.55785408e-08 5.51055320e-08\n",
      "  5.53420364e-08 5.55785408e-08 6.03086294e-08 1.37172569e-08]\n",
      " [1.22982303e-08 5.93626117e-08 5.22674788e-08 5.34500010e-08\n",
      "  5.36865054e-08 5.32134965e-08 5.32134965e-08 5.32134965e-08\n",
      "  5.34500010e-08 5.34500010e-08 5.32134965e-08 5.36865054e-08\n",
      "  5.46325231e-08 5.41595143e-08 5.48690275e-08 5.65245585e-08\n",
      "  5.79435851e-08 5.91261073e-08 5.93626117e-08 5.95991161e-08\n",
      "  6.00721250e-08 6.00721250e-08 5.95991161e-08 6.00721250e-08\n",
      "  5.95991161e-08 5.55785408e-08 6.03086294e-08 0.00000000e+00]\n",
      " [7.33163730e-09 4.91929212e-08 5.43960187e-08 5.51055320e-08\n",
      "  5.51055320e-08 5.60515497e-08 5.58150453e-08 5.58150453e-08\n",
      "  5.69975674e-08 5.55785408e-08 5.69975674e-08 5.84165940e-08\n",
      "  5.93626117e-08 6.00721250e-08 5.72340718e-08 5.58150453e-08\n",
      "  5.51055320e-08 5.36865054e-08 5.17944700e-08 4.77738947e-08\n",
      "  4.56453548e-08 4.46993371e-08 4.39898238e-08 4.28073017e-08\n",
      "  4.04422574e-08 3.90232308e-08 4.49358415e-08 9.93318602e-09]\n",
      " [1.82108410e-08 4.70643814e-08 4.06787618e-08 4.44628327e-08\n",
      "  4.70643814e-08 4.77738947e-08 5.15579655e-08 5.17944700e-08\n",
      "  5.20309744e-08 5.41595143e-08 5.53420364e-08 5.25039833e-08\n",
      "  5.03754434e-08 4.94294257e-08 4.89564168e-08 4.96659301e-08\n",
      "  4.80103991e-08 4.35168149e-08 3.59486732e-08 4.04422574e-08\n",
      "  3.90232308e-08 3.83137175e-08 3.83137175e-08 3.94962397e-08\n",
      "  3.97327441e-08 3.71311954e-08 4.54088504e-08 1.84473455e-08]\n",
      " [0.00000000e+00 1.06426993e-08 2.38869473e-08 3.31106201e-08\n",
      "  3.76042042e-08 4.11517707e-08 4.30438061e-08 4.39898238e-08\n",
      "  4.37533194e-08 4.44628327e-08 4.61183637e-08 4.65913725e-08\n",
      "  4.44628327e-08 4.13882751e-08 3.14550891e-08 1.65553100e-08\n",
      "  4.49358415e-09 0.00000000e+00 0.00000000e+00 4.94294257e-08\n",
      "  5.46325231e-08 5.15579655e-08 5.25039833e-08 5.29769921e-08\n",
      "  5.36865054e-08 5.13214611e-08 5.41595143e-08 2.19949119e-08]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.73008858e-10 5.67610630e-09\n",
      "  8.75066388e-09 1.06426993e-08 7.56814173e-09 4.25707972e-09\n",
      "  2.60154872e-09 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 1.70283189e-08\n",
      "  1.20617259e-08 1.25347347e-08 8.75066388e-09 8.04115059e-09\n",
      "  6.85862844e-09 7.33163730e-09 1.18252215e-09 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[42])\n",
    "print('This Image Is Labelled By The Neural Network As ' + str(train_labels[42]))\n",
    "print(train_images[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look how the plotted values above are actually forming a rough shape of the ankle boot.\n",
    "\n",
    "Now, Our image has values from zero to 255, but <b>neural networks work better with normalized data</b>. So, let's change it to between zero and one simply by dividing every value by 255. In Python, you can actually divide an entire array with one line of code like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images /255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 2.3028 - accuracy: 0.0979\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 2.3028 - accuracy: 0.0973\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 2.3028 - accuracy: 0.0963\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 2.3027 - accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 2.3028 - accuracy: 0.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17baef5f308>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = tf.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
